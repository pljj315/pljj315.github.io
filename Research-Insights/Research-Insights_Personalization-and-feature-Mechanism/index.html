

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/imgs/img/OIP.jpg">
  <link rel="icon" href="/imgs/img/OIP.jpg">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="pljj315">
  <meta name="keywords" content="计算机视觉 视觉大模型 研究生生活">
  
    <meta name="description" content="Research Insights: diffusion VS control文章目的：从大四接触diffusion到现在已经接近2年，温故而知新，最近在回顾之前阅读过的工作，也总结一下在control方面的技术发展路线，看看能否给带来点启发。谈到control技术的分类，很多工作被统一归纳为“encoder-based methods”，但这种归纳还是太”大“了，这里用我自己的理解做一些更细致的">
<meta property="og:type" content="article">
<meta property="og:title" content="Research Insights: diffusion VS control">
<meta property="og:url" content="https://pljj315.github.io/Research-Insights/Research-Insights_Personalization-and-feature-Mechanism/index.html">
<meta property="og:site_name" content="JH_BLOG">
<meta property="og:description" content="Research Insights: diffusion VS control文章目的：从大四接触diffusion到现在已经接近2年，温故而知新，最近在回顾之前阅读过的工作，也总结一下在control方面的技术发展路线，看看能否给带来点启发。谈到control技术的分类，很多工作被统一归纳为“encoder-based methods”，但这种归纳还是太”大“了，这里用我自己的理解做一些更细致的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pljj315.github.io/imgs/personalization-and-feature-mechanism/image-20250109172222535.png">
<meta property="article:published_time" content="2025-01-09T02:56:23.000Z">
<meta property="article:modified_time" content="2025-04-18T07:30:18.434Z">
<meta property="article:author" content="pljj315">
<meta property="article:tag" content="diffusion;">
<meta property="article:tag" content="control;">
<meta property="article:tag" content="text-to-img;">
<meta property="article:tag" content="img-to-img;">
<meta property="article:tag" content="大模型；">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://pljj315.github.io/imgs/personalization-and-feature-mechanism/image-20250109172222535.png">
  
  
  
  <title>Research Insights: diffusion VS control -&gt; JH_BLOG</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"pljj315.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":30,"cursorChar":":","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":"❡"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/imgs/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>pljj315&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/imgs/img/default_roy.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Research Insights: diffusion VS control"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        pljj315
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-01-09 10:56" pubdate>
          2025年1月9日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          18 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Research Insights: diffusion VS control</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Research-Insights-diffusion-VS-control"><a href="#Research-Insights-diffusion-VS-control" class="headerlink" title="Research Insights: diffusion VS control"></a>Research Insights: diffusion VS control</h1><p>文章目的：从大四接触diffusion到现在已经接近2年，温故而知新，最近在回顾之前阅读过的工作，也总结一下在control方面的技术发展路线，看看能否给带来点启发。谈到control技术的分类，很多工作被统一归纳为“encoder-based methods”，但这种归纳还是太”大“了，这里用我自己的理解做一些更细致的分类，分类依据更偏向于具体的<em>特征注入机制&#x2F;控制机制</em>。</p>
<hr>
<p>encoder-based methods如何理解？：从特征的提取encoder角度入手，着重于将“<strong>不同的image-feature以及不同的特征提取方式</strong>” + “<strong>不同的control控制机制</strong>” 做排列组合。</p>
<p>比如 IC-light 使用可训练的 MLP 提取环境贴图的hdr-envmap-embedding + <strong>stacked into text_embedding</strong>控制机制，</p>
<p>比如 Instant-ID 使用人脸识别器提取face-embedding + <strong>IP-A</strong> 、人脸关键点facial-keypoints + <strong>ControlNet</strong> 控制机制，</p>
<p>比如 Anydoor 使用：sobel算子提取的高频信息map与背景和位置+<strong>ControlNet</strong>控制机制、DINO-V2提取的特征+<strong>stacked into text_embedding</strong>控制机制，</p>
<p>比如 AnyText 使用OCR文字识别器提取glyph-embedding + <strong>ControlNet</strong>控制机制……</p>
<p>似乎是只要找到能用来提取特征的特征提取器（一般借鉴传统算法），再结合某种特定的控制机制，就能注入各种形式的条件特征。本文不介绍“不同的image-feature以及不同的特征提取方式”，着重介绍 “不同的control控制机制” 的技术路线。</p>
<hr>
<p>条件控制的文生图目标：期待在文本提示基础上，能够参考到来自图像的提示，毕竟有些提示不是言辞能够表达的，“词不达意”，图片能够蕴含更多信息也更贴近人类视觉观察的维度。本文的control主要是指除了文本提示以外的其他提示（即，图像）。</p>
<blockquote>
<p>回顾文本条件注入：基础的文生图模型，如LDM(latent diffusion model)中文本条件注入机制：text-encoder + cross-attention[text-embedding作为Key&#x2F;Value]；</p>
<p>回顾微调：最初的探索阶段涌现出的微调手段，如Dreambooth，Textual-Inversion，LoRA…目前LoRA依然具有很强的应用能力。</p>
</blockquote>
<h2 id="1-ControlNet系列"><a href="#1-ControlNet系列" class="headerlink" title="1. ControlNet系列"></a>1. ControlNet系列</h2><p>太经典了，不必多说：ControlNet引入结构控制：zero-initialization + copyed half_unet,  residual思想：直接相加；💥</p>
<p>论文举例：（略）</p>
<ul>
<li>ControlNet</li>
<li>T2I-adapter</li>
<li>Uni-ControlNet</li>
</ul>
<blockquote>
<p>注：基本没使用 image-encoder，不算是encoder-based的一种，但经常与encoder-based结合，可以成为controlnet-based？毕竟controlnet就是非常简单粗暴，直接copy后就开始无脑学…</p>
</blockquote>
<h2 id="2-stacked-into-text-token-基本不再使用"><a href="#2-stacked-into-text-token-基本不再使用" class="headerlink" title="2. stacked into text_token-基本不再使用"></a>2. stacked into text_token-基本不再使用</h2><p>概括：把<strong>CLIP image encoder</strong>提取到的图像特征作为文本，替换text中的伪词，然后得到新的融合text_embedding，作为 cross-attention的 Key&#x2F;Value 注入unet，以指导图像生成。由于需要额外训练text-encoder，此策略基本已被抛弃，虽然但是，下面两篇文章与IP-A时间相近，都利用了解耦的cross-attention！</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2302.13848">ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation</a>-2023.8</p>
<ul>
<li>策略：发现本文发行的时间与IP-A很近？也算是IP-A类似，不过在text-cross-attention中掺杂了<strong>stacked into text_embedding</strong>的类似策略，可以说是stacked into text_token；现在一般都是在embedding层面的融入，即在text-encoder之后的融入。</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05793">PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models</a>-2023.9</p>
</li>
</ul>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109172222535.png" srcset="/imgs/img/loading.gif" lazyload alt="左图为PhotoVerse-右图为ELITE" title="左图为PhotoVerse-右图为ELITE"></p>
<h2 id="3-stacked-into-text-embedding"><a href="#3-stacked-into-text-embedding" class="headerlink" title="3. stacked into text_embedding:"></a>3. stacked into text_embedding:</h2><p>概括：把<strong>CLIP image encoder</strong>提取到的图像特征，与文本特征向量（即text_embedding）<strong>拼接concatenate</strong>或者<strong>替换replace</strong>，得到的融合特征作为 cross-attention的 Key&#x2F;Value 注入unet，以指导图像生成。</p>
<p>缺点：生成的图像只是部分忠实于图像提示，对图像提示的表现力不如微调（如LoRA）。</p>
<blockquote>
<p>与上段 stacked into text_token 的区别是：clip-image-feature是在哪个维度与text条件融合的，一个是在token甚至是纯文本阶段，一个是在文本嵌入向量阶段。前者基本已被淘汰，后者在特征空间的维度上融合更合理。</p>
</blockquote>
<p>论文举例：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09481">AnyDoor: Zero-shot Object-level Image Customization</a>-2023.7 阿里巴巴 蚂蚁</p>
<ul>
<li><p>策略：sobel算子提取的高频信息map与背景和位置+<strong>ControlNet</strong> 、DINO-V2提取物体的信息特征+<strong>stacked into text_embedding</strong>；</p>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109154914240.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109154914240" title="anydoor结构"></p>
</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.04461">PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</a>-2023.12  已开源</p>
<ul>
<li><p>策略：利用CLIP-image-encoder提取具有人像信息的image-feature，经过<strong>MLP</strong>，替换原始文本中“男人”或者“女人”对应的embedding作为新的“text_embedding”。</p>
</li>
<li><p>优点：由于保持了text_embedding的存在，对原始底膜的语义遵循没太大影响，语义一致性不错；</p>
</li>
<li><p>缺点：仅使用更新的带有人像信息的“text_embedding”，对人像信息控制不充分，人像保持差；</p>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109113515713.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109113515713"></p>
</li>
</ul>
</li>
</ul>
<h2 id="4-cross-attention-mechanism✨"><a href="#4-cross-attention-mechanism✨" class="headerlink" title="4. cross-attention mechanism✨:"></a>4. cross-attention mechanism✨:</h2><p>概括：在上文中提到的注意力机制中，每个注意力层都只包括了1个self-attention、1个cross-attention，并在这1个cross-attention中注入”由文本提升和图像提示融合得到的条件特征”【融合条件特征作为cross-attention的 Key&#x2F;Value】。由此出发的改进策略：将<strong>注意力解耦</strong>，即把“文本条件特征”与“图像条件特征”分开，分别注入到2个不同的cross-attention中去，再进行相加。</p>
<p>优点：图像提示拥有了与文本提示“同等地位”的控制权，能够更好的听图像提示的话！</p>
<p>论文举例：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06721">IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models</a>-2023.8 腾讯✨</p>
<ul>
<li><p>策略：利用<strong>CLIP-image-encoder</strong>提取具有图像的image-feature，经过<strong>Linear+LayerNorm</strong>，将<strong>注意力解耦</strong>，即把“文本条件特征”与“图像条件特征”分开，分别注入到2个不同的cross-attention中去[ <em>text-cross-attention与image-cross-attention</em> ]，再将2个cross-attention结果进行相加。</p>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109143750831.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109143750831"></p>
</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.11781">Infinite-ID: Identity-preserved Personalization via ID-semantics Decoupling Paradigm</a>-2024.3 中科大 没开源</p>
<ul>
<li>策略：与IP-A类似，只不过在imgae-feature提取这有所增添：除了来自CLIP-image-encoder提取的人像信息【后续称为clip-image-embedding】，还使用了来自<strong>人脸识别器</strong>提取的face-embedding，并将两者<strong>拼接concat</strong>，拼接后一齐作为图像条件特征（<strong>IP-A</strong>）。</li>
<li>训练策略：训练时，只使用图像输入，不使用caption。据说能够增强对图像的学习。</li>
<li>除此之外，风格控制方面还使用了AdaIN-m机制，主要是在self-attention上做了改动。</li>
<li><img src="/../imgs/personalization-and-feature-mechanism/image-20250109152153105.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109152153105"></li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.07519">InstantID: Zero-shot Identity-Preserving Generation in Seconds</a>-2024.2 InstantX、小红书</p>
<ul>
<li><p>策略：与Infinite-ID类似，也是在图像特征提取上做了改动：直接放弃CLIP-image-encoder，只使用人脸模型提取的face-embedding作为图像条件特征（<strong>IP-A</strong>）。除此之外，还使用了人脸关键点图结合<strong>ControlNet</strong>进行人脸五官位置的结构控制。</p>
</li>
<li><blockquote>
<p>注意：ControlNet不再使用text-embedding，只使用face-embedding。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="5-double-UNet-mechanism✨"><a href="#5-double-UNet-mechanism✨" class="headerlink" title="5. double UNet mechanism✨:"></a>5. double UNet mechanism✨:</h2><p>概括：经过大量数据预训练的diffusion model本身已经具有了很强大的对图像提取特征的能力，那可以直接拿来替换&#x2F;作为上文的各种image-encoder啊！具体从哪层”拿“还挺值得研究，下面的两篇都是拿的ref_unet中的self-attention输出的feature，<strong>？？？？为什么呢</strong>。</p>
<p>论文举例：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.00973">Intelligent Grimm – Open-ended Visual Storytelling via Latent Diffusion Models</a>-2024.3 已开源✨</p>
<ul>
<li>策略：可以理解为IP-A的变种：依然是解耦的cross-attention，不过新增的image-cross-attention的keys&#x2F;values不再是直接用image-encoder提取的image-feature，用的是参考图像的”ref_unet”流程中<strong>ref-self-attention后得到的ref-unet-feature</strong>。</li>
</ul>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109164719609.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109164719609"></p>
</li>
<li><p>[Improving Diffusion Models for Authentic Virtual Try-on in the Wild]([<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.05139">2403.05139] Improving Diffusion Models for Authentic Virtual Try-on in the Wild</a>)-2024.3 KAIST 已开源✨</p>
<ul>
<li>策略：本文拿的也是”ref_unet”流程中<strong>ref-self-attention后得到的ref-unet-feature</strong>，与Intelligent Grimm不同的是：本文不再将其作为cross-attention的keys&#x2F;values，而是与hidden-states拼接作为新的Query作用到self-attention。</li>
<li>疑问：关于high-level、low-level如何理解？</li>
</ul>
</li>
</ul>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109173953044.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109173953044" title="IDM–VTON结构"></p>
<h2 id="6-novel-loss"><a href="#6-novel-loss" class="headerlink" title="6. novel loss"></a>6. novel loss</h2><p>在diffusion中常见的loss是：由unet预测到的噪声与真实噪声之间的MSE均方差loss，被称作vanilla-loss或naive-loss：</p>
<p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109160403306.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109160403306"></p>
<p>论文举例：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.16022">PuLID: Pure and Lightning ID Customization via Contrastive Alignment</a>-2024.4 字节<ul>
<li>策略：利用加速模型（如Lightning T2I），在训练过程中增加对比loss，不对原模型能力做出破坏。<strong>IP-A</strong>+ <strong>Lightning T2I</strong>+使用额外的loss设计，包括在unet内部的aligh_loss和unet外部的id_loss；</li>
<li>优点：一个路径仅受提示的条件，而另一个路径使用ID和提示作为条件。通过在语义上对齐这两条路径上的UNET特征（即，Qt与Qtid），模型将学习如何在不影响原始模型行为的情况下嵌入ID。</li>
<li>缺点：增加耗时。？</li>
</ul>
</li>
</ul>
<p>​		<img src="/../imgs/personalization-and-feature-mechanism/image-20250109161049551.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109161049551"></p>
<p>​		<img src="/../imgs/personalization-and-feature-mechanism/image-20250109161355622.png" srcset="/imgs/img/loading.gif" lazyload alt="image-20250109161355622"></p>
<p>待看：</p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.16537">Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization</a>-2024.6</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Research-Insights/" class="category-chain-item">Research Insights</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/diffusion/" class="print-no-link">#diffusion;</a>
      
        <a href="/tags/control/" class="print-no-link">#control;</a>
      
        <a href="/tags/text-to-img/" class="print-no-link">#text-to-img;</a>
      
        <a href="/tags/img-to-img/" class="print-no-link">#img-to-img;</a>
      
        <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%9B/" class="print-no-link">#大模型；</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Research Insights: diffusion VS control</div>
      <div>https://pljj315.github.io/Research-Insights/Research-Insights_Personalization-and-feature-Mechanism/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>pljj315</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年1月9日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/LeetCode-highlights/LeetCode-Highlights/" title="算法——leetcode">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">算法——leetcode</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/paper-reading/Paper-Reading_Nested-Attention/" title="paper reading: Nested Attention: Semantic-aware Attention Values for Concept Personalization-2025">
                        <span class="hidden-mobile">paper reading: Nested Attention: Semantic-aware Attention Values for Concept Personalization-2025</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"Ov23lipwdnWHzn8s0j4d","clientSecret":"794682cc1d531e3af88ba187be170008cdb87097","repo":"pljj315.github.io","owner":"pljj315","admin":["pljj315"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: 'cdb37dfb83498a81d264a934a257519f'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <i class="iconfont icon-love"></i> <a href="https://github.com/pljj315" target="_blank" rel="nofollow noopener"><span>github</span></a> <i class="iconfont icon-love"></i> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="/js/leancloud.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>

<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>算法——leetcode</title>
    <link href="/uncategorized/record_leetcode/"/>
    <url>/uncategorized/record_leetcode/</url>
    
    <content type="html"><![CDATA[<p>刷题以及快速刷题的技巧：</p><p>先掌握好数据结构以及对应的常考算法，对应着下述刷题规划网站思考+看题解；先在心里大概记忆算法和对应的示例题目，快速了解算法。</p><p>自己计算空间复杂度、时间复杂度；</p><h2 id="算法讲解、刷题路线规划：好用网站"><a href="#算法讲解、刷题路线规划：好用网站" class="headerlink" title="算法讲解、刷题路线规划：好用网站"></a>算法讲解、刷题路线规划：好用网站</h2><ol><li><a href="https://programmercarl.com/">代码随想录</a></li><li><a href="https://labuladong.online/algo/home/">labuladong算法笔记</a></li><li><a href="https://github.com/CyC2018/CS-Notes.git">github-技术面试及刷题整理-CS-Notes</a></li></ol><p>总体路线：数据结构 + 算法：经典题</p><h2 id="算法书籍："><a href="#算法书籍：" class="headerlink" title="算法书籍："></a>算法书籍：</h2><ol><li>剑指offer 系列</li></ol><h2 id="算法知识点-简记"><a href="#算法知识点-简记" class="headerlink" title="算法知识点-简记"></a>算法知识点-简记</h2><h3 id="·-数据结构"><a href="#·-数据结构" class="headerlink" title="· 数据结构"></a>· 数据结构</h3><ol><li><p>数组：</p><ol><li>特点：内存连续，查询快速，增删复杂；</li><li>算法要点：二分查找，<strong>双指针</strong>（覆盖移除、快慢双指针、左右双指针），<strong>前缀和</strong>&#x2F;区间和；.sort()原地排序；</li><li>二分法：有序数组的mid中位数为界定的：<em>排除法</em>！！时间复杂度O(logn)</li></ol></li><li><p>链表：单链表、双向链表、循环链表；</p><ol><li><p>特点：内存不联系，查询慢速，增删容易；</p></li><li><p>算法要点：虚拟头结点、构建类（增删查改）、双指针（快n步双指针）、环形链表（数学推理）；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ListNode</span>:     <span class="hljs-comment"># 单链表</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val=<span class="hljs-number">0</span>, <span class="hljs-built_in">next</span>=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-variable language_">self</span>.val = val<br>        <span class="hljs-variable language_">self</span>.<span class="hljs-built_in">next</span> = <span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ListNode</span>:     <span class="hljs-comment"># 双链表</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val=<span class="hljs-number">0</span>, prev=<span class="hljs-literal">None</span>, <span class="hljs-built_in">next</span>=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-variable language_">self</span>.val = val<br>        <span class="hljs-variable language_">self</span>.prev = prev<br>        <span class="hljs-variable language_">self</span>.<span class="hljs-built_in">next</span> = <span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure></li></ol></li><li><p>哈希表&#x2F;散列表：<strong>数组、set集合、map映射</strong></p><ol><li><p>特点：查询特别快O(1)、底层包括哈希映射+哈希碰撞；</p><blockquote><p>当需要查询一个元素是否出现过、或者一个元素是否在集合里时，第一时间想到哈希法</p></blockquote></li><li><p>hash table的3中结构区别：</p><ul><li>作为哈希表的数组：已知数据长度<strong>才能且最好用</strong>数组，更快（不需要哈希映射计算）；</li><li>作为哈希表的set：集合，只存储key，需要哈希映射运算去计算内存地址；</li><li>作为哈希表的map【dict字典】：【key-value】结构；</li></ul></li><li><p>算法要点：先构建+再快速查询、n数和、结合双指针；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict, Counter<br><br><span class="hljs-built_in">dict</span>.get(get_val, set_val_if_cannot_get)<br><br><span class="hljs-built_in">set</span>() &amp; <span class="hljs-built_in">set</span>() <span class="hljs-comment"># 集合相与</span><br></code></pre></td></tr></table></figure></li></ol></li><li><p>字符串：</p><ol><li><p>算法要点：切片[::-1]、<strong>KMP前缀匹配-next前缀表</strong>O(m+n)、双指针；</p><blockquote><p>前缀表&#x3D;最长公共前后缀长度表&#x3D;next数组【原始、右移、减一】：j&#x3D;next[index-1] </p><p>讲解：<a href="https://programmercarl.com/0028.%E5%AE%9E%E7%8E%B0strStr.html">实现strStr() KMP前缀表+next数组、prefix数组</a></p></blockquote></li></ol></li><li><p>栈与队列：</p><ol><li>特点：<ul><li><strong>栈—实现了—&gt;递归</strong>：先进后出；出栈.pop()、查询栈顶[-1]</li><li>队列：先进先出；入队.append()、查询队首[0] <code>from collections import deque;   .popleft()</code></li><li>优先级队列&#x3D;堆：大顶堆、小顶堆（<strong>完全二叉树+且树中每个结点的值都不小于（或不大于）其左右孩子的值</strong>）<code>import heapq;   heapq.heappop(pri_que)</code></li></ul></li><li>算法要点：<strong>单调队列:push之前把前面小的删掉，队列永远是单调递减的</strong>：.pop()、单调栈【下一更大元素】时间复杂度O(n)</li></ol></li><li><p>二叉树：</p><ol><li><p>种类：</p><ol><li>满二叉树：如果一棵二叉树只有度为0的结点和度为2的结点，并且度为0的结点在同一层上，则这棵二叉树为满二叉树</li><li>完全二叉树：在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层（h从1开始），则该层包含 1~ 2^(h-1) 个节点<ul><li>所有层（除了最后一层）都完全填满。</li><li>最后一层的节点尽可能靠左填充。</li><li>不要求所有叶子节点在同一层。</li></ul></li><li>完美二叉树、完整二叉树:<ul><li>所有层都完全填满。</li><li>所有叶子节点都在同一层。</li><li>每个非叶子节点都有两个子节点。</li></ul></li><li>二叉搜索树：<ol><li>若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</li><li>若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</li><li>它的左、右子树也分别为二叉排序树</li></ol></li><li>平衡二叉树：二叉树每个节点的左右两个子树的**高度【后序遍历】**差的绝对值不超过1;</li></ol></li><li><p>存储：</p><ol><li><p>链式存储：左右指针 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TreeNode</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val, left = <span class="hljs-literal">None</span>, right = <span class="hljs-literal">None</span></span>):<br>        <span class="hljs-variable language_">self</span>.val = val<br>        <span class="hljs-variable language_">self</span>.left = left<br>        <span class="hljs-variable language_">self</span>.right = right<br></code></pre></td></tr></table></figure></li><li><p>顺序存储：内存是连续分布——数组</p></li></ol></li><li><p>遍历：</p><ol><li>深度优先遍历：<ul><li>前序遍历（递归法，迭代法<strong>用栈去实现</strong>）</li><li>中序遍历（递归法，迭代法<strong>用栈去实现</strong>）</li><li>后序遍历（递归法，迭代法<strong>用栈去实现</strong>）</li><li><em>二叉树的递归3步：确定递归函数的参数和返回值–&gt;确定终止条件–&gt;确定单层递归的逻辑</em></li></ul></li><li>广度优先遍历：<ul><li>层次遍历（迭代法<strong>用队列取实现</strong>）<code>queue = collections.deque([root]); queue.append(); queue.popleft()</code></li></ul></li></ol></li><li><p>深度、高度：求深度可以从上到下去查&#x3D;&#x3D;&gt;前序遍历（中左右），高度只能从下到上去查&#x3D;&#x3D;&gt;后序遍历（左右中）</p><p><img src="https://code-thinking-1253855093.file.myqcloud.com/pics/20210203155515650.png" alt="110.平衡二叉树2"></p></li><li><p>算法要点：遍历（前中后**、层序遍历**）、深度&#x2F;高度、节点个数、<strong>路径【回溯】</strong>、构造与修改、公共祖先; 递归 VS 迭代 <a href="https://programmercarl.com/0257.%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84.html#%E5%85%B6%E4%BB%96%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC">二叉树的所有路径：回溯</a>、左叶子之和，平衡二叉搜索树BST的构建；</p></li></ol></li></ol><h3 id="·-算法思想"><a href="#·-算法思想" class="headerlink" title="· 算法思想"></a>· 算法思想</h3><ol><li><p>排序</p></li><li><p>回溯</p><ol><li><p>适用问题：<strong>组合问题和分割问题都是收集树的叶子节点，而子集问题是找树的所有节点！</strong></p><ul><li>组合问题：N个数里面按一定规则找出k个数的集合：</li><li>切割问题：一个字符串按一定规则有几种切割方式</li><li>子集问题：一个N个数的集合里有多少符合条件的子集</li><li>排列问题：N个数按一定规则全排列，有几种排列方式：每层都从0开始搜索而不是startIndex、需要used数组记录已使用过元素集；</li><li>棋盘问题：N皇后，解数独等等</li></ul></li><li><p>算法特点：递归（本质是穷举）<strong>回溯可以被抽象为树形结构【N叉树】</strong>；场景：在同一个&#x2F;不同多个 集合中递归查找子集，<strong>集合的大小就构成了树的宽度，递归的深度就构成了树的深度</strong>。 —— “N叉树的层序遍历：<strong>for循环横向遍历，递归纵向遍历，回溯不断调整结果集</strong>。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs text">3步曲：<br>1. 回溯函数的模板返回值【void】以及参数<br>2. 回溯函数的终止条件<br>3. 回溯搜索的遍历过程<br><br>void backtracking(参数) &#123;<br>    if (终止条件) &#123;<br>        存放结果;<br>        return;&#125;<br>    for (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;<br>        处理节点;<br>        backtracking(路径，选择列表); // 递归<br>        回溯，撤销处理结果<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://code-thinking-1253855093.file.myqcloud.com/pics/20210130173631174.png" alt="回溯算法理论基础"></p></li><li><p>注意：</p><ul><li>集合中的元素不能重复使用时：需要startIndex调整下一层递归的起始位置；</li><li><strong>横向去重【排序后+used标记、for外used哈希表&#x2F;哈希数组标记】</strong>、纵向去重[startIndex]；</li></ul></li></ol></li><li><p>贪心</p><ol><li>特点：<strong>选择每一阶段&#x2F;状态的局部最优，从而达到全局最优</strong></li><li>经典例题：跳跃游戏、重叠区间（先排序）、发饼干</li></ol></li><li><p>动态规划</p><ol><li><p>特点：<strong>需要对前一个状态进行推导</strong></p></li><li><p>动态规划5步曲：</p><ul><li><p>确定dp数组（dp table）以及下标的含义</p></li><li><p>确定递推公式</p></li><li><p>dp数组如何初始化</p></li><li><p>确定遍历顺序</p></li><li><p>举例推导dp数组——打印dp数组debug</p><pre><code class="hljs">      # 动态规划：      # 1. 结合题干-dp含义:dp      # 2. 递归公式       # 3. 初始化       # 4. 遍历顺序      # 5. 打印dp数组</code></pre></li></ul><p><code> </code></p></li><li><p>经典例题：斐波那契、爬楼梯、整数拆分<img src="https://kstar-1253855093.cos.ap-nanjing.myqcloud.com/baguwenpdf/_%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE_%E9%9D%92.png" alt="img"></p></li><li><p>打家劫舍问题——【树形dp遍历】</p></li><li><p>股票问题——</p></li><li><p>子序列、子数组&#x3D;&#x3D;连续子序列 问题：</p><pre><code class="hljs">    # 子序列  vs  子数组：子数组要求连续！！！    最长公共子序列：二维dp    # 子序列：dp[i][j]表示nums1:0~i-1 与 nums2:0~j-1的最长公共子的长度    # 递归公式：if nums1[i-1]==nums2[j-1]:dp[i][j] = dp[i-1][j-1]+1, else: max(dp[i-1][j], dp[i][j-1])    # 子数组==连续子序列：dp[i][j]表示以nums1[i-1] 与 nums2[j-1]结尾的、最长公共子数组的长度    # 递归公式：if nums1[i-1]==nums2[j-1]:dp[i][j] = dp[i-1][j-1]+1, else:0</code></pre></li><li><p>编辑距离问题——增删改: 二维dp数组；</p></li><li><p>回文子串问题——布尔类型的dp[i]-[j]：表示区间范围[i,j] （注意是左闭右闭）的子串是否是回文子串，如果是：dp[i]-[j]为true，否则为false</p></li><li><p>背包问题——二维dp数组  or 一维dp数组：<strong>dp[i]-[j] 表示从下标为[0-i]的物品里任意取，放进容量为j的背包，价值总和最大是多少：dp[i]·[j] &#x3D; max( dp[ i - 1 ]·[ j ] ,     dp[ i - 1 ]·[ j- weight[ i ] ] + value[ i ] )</strong></p><ul><li>01背包：一维dp数组：先物品 再倒序背包</li><li>完全背包：一维dp数组：组合{先物品 再正序背包}、排列{先正序背包 再物品}</li></ul><p><img src="https://code-thinking-1253855093.file.myqcloud.com/pics/20210117171307407.png" alt="416.背包问题-分割等和子集1"></p></li></ol></li><li><p>图论</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>leetcode刷题</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>技术路线总结: diffusion VS control</title>
    <link href="/%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF%E6%80%BB%E7%BB%93/personalization-and-feature-mechanism/"/>
    <url>/%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF%E6%80%BB%E7%BB%93/personalization-and-feature-mechanism/</url>
    
    <content type="html"><![CDATA[<p>文章目的：从大四接触diffusion到现在已经接近2年，温故而知新，最近在回顾之前阅读过的工作，也总结一下在control方面的技术发展路线，看看能否给带来点启发。谈到control技术的分类，很多工作被统一归纳为“encoder-based methods”，但这种归纳还是太”大“了，这里用我自己的理解做一些更细致的分类，分类依据更偏向于具体的<em>特征注入机制&#x2F;控制机制</em>。</p><hr><p>encoder-based methods如何理解？：从特征的提取encoder角度入手，着重于将“<strong>不同的image-feature以及不同的特征提取方式</strong>” + “<strong>不同的control控制机制</strong>” 做排列组合。</p><p>比如 IC-light 使用可训练的 MLP 提取环境贴图的hdr-envmap-embedding + <strong>stacked into text_embedding</strong>控制机制，</p><p>比如 Instant-ID 使用人脸识别器提取face-embedding + <strong>IP-A</strong> 、人脸关键点facial-keypoints + <strong>ControlNet</strong> 控制机制，</p><p>比如 Anydoor 使用：sobel算子提取的高频信息map与背景和位置+<strong>ControlNet</strong>控制机制、DINO-V2提取的特征+<strong>stacked into text_embedding</strong>控制机制，</p><p>比如 AnyText 使用OCR文字识别器提取glyph-embedding + <strong>ControlNet</strong>控制机制……</p><p>似乎是只要找到能用来提取特征的特征提取器（一般借鉴传统算法），再结合某种特定的控制机制，就能注入各种形式的条件特征。本文不介绍“不同的image-feature以及不同的特征提取方式”，着重介绍 “不同的control控制机制” 的技术路线。</p><hr><p>条件控制的文生图目标：期待在文本提示基础上，能够参考到来自图像的提示，毕竟有些提示不是言辞能够表达的，“词不达意”，图片能够蕴含更多信息也更贴近人类视觉观察的维度。本文的control主要是指除了文本提示以外的其他提示（即，图像）。</p><blockquote><p>回顾文本条件注入：基础的文生图模型，如LDM(latent diffusion model)中文本条件注入机制：text-encoder + cross-attention[text-embedding作为Key&#x2F;Value]；</p><p>回顾微调：最初的探索阶段涌现出的微调手段，如Dreambooth，Textual-Inversion，LoRA…目前LoRA依然具有很强的应用能力。</p></blockquote><h2 id="1-ControlNet系列"><a href="#1-ControlNet系列" class="headerlink" title="1. ControlNet系列"></a>1. ControlNet系列</h2><p>太经典了，不必多说：ControlNet引入结构控制：zero-initialization + copyed half_unet,  residual思想：直接相加；💥</p><p>论文举例：（略）</p><ul><li>ControlNet</li><li>T2I-adapter</li><li>Uni-ControlNet</li></ul><blockquote><p>注：基本没使用 image-encoder，不算是encoder-based的一种，但经常与encoder-based结合，可以成为controlnet-based？毕竟controlnet就是非常简单粗暴，直接copy后就开始无脑学…</p></blockquote><h2 id="2-stacked-into-text-token-基本不再使用"><a href="#2-stacked-into-text-token-基本不再使用" class="headerlink" title="2. stacked into text_token-基本不再使用"></a>2. stacked into text_token-基本不再使用</h2><p>概括：把<strong>CLIP image encoder</strong>提取到的图像特征作为文本，替换text中的伪词，然后得到新的融合text_embedding，作为 cross-attention的 Key&#x2F;Value 注入unet，以指导图像生成。由于需要额外训练text-encoder，此策略基本已被抛弃，虽然但是，下面两篇文章与IP-A时间相近，都利用了解耦的cross-attention！</p><ul><li><p><a href="http://arxiv.org/abs/2302.13848">ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation</a>-2023.8</p><ul><li>策略：发现本文发行的时间与IP-A很近？也算是IP-A类似，不过在text-cross-attention中掺杂了<strong>stacked into text_embedding</strong>的类似策略，可以说是stacked into text_token；现在一般都是在embedding层面的融入，即在text-encoder之后的融入。</li></ul></li><li><p><a href="http://arxiv.org/abs/2309.05793">PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models</a>-2023.9</p></li></ul><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109172222535.png" alt="左图为PhotoVerse-右图为ELITE" title="左图为PhotoVerse-右图为ELITE"></p><h2 id="3-stacked-into-text-embedding"><a href="#3-stacked-into-text-embedding" class="headerlink" title="3. stacked into text_embedding:"></a>3. stacked into text_embedding:</h2><p>概括：把<strong>CLIP image encoder</strong>提取到的图像特征，与文本特征向量（即text_embedding）<strong>拼接concatenate</strong>或者<strong>替换replace</strong>，得到的融合特征作为 cross-attention的 Key&#x2F;Value 注入unet，以指导图像生成。</p><p>缺点：生成的图像只是部分忠实于图像提示，对图像提示的表现力不如微调（如LoRA）。</p><blockquote><p>与上段 stacked into text_token 的区别是：clip-image-feature是在哪个维度与text条件融合的，一个是在token甚至是纯文本阶段，一个是在文本嵌入向量阶段。前者基本已被淘汰，后者在特征空间的维度上融合更合理。</p></blockquote><p>论文举例：</p><ul><li><p><a href="http://arxiv.org/abs/2307.09481">AnyDoor: Zero-shot Object-level Image Customization</a>-2023.7 阿里巴巴 蚂蚁</p><ul><li><p>策略：sobel算子提取的高频信息map与背景和位置+<strong>ControlNet</strong> 、DINO-V2提取物体的信息特征+<strong>stacked into text_embedding</strong>；</p><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109154914240.png" alt="image-20250109154914240" title="anydoor结构"></p></li></ul></li><li><p><a href="http://arxiv.org/abs/2312.04461">PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</a>-2023.12  已开源</p><ul><li><p>策略：利用CLIP-image-encoder提取具有人像信息的image-feature，经过<strong>MLP</strong>，替换原始文本中“男人”或者“女人”对应的embedding作为新的“text_embedding”。</p></li><li><p>优点：由于保持了text_embedding的存在，对原始底膜的语义遵循没太大影响，语义一致性不错；</p></li><li><p>缺点：仅使用更新的带有人像信息的“text_embedding”，对人像信息控制不充分，人像保持差；</p><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109113515713.png" alt="image-20250109113515713"></p></li></ul></li></ul><h2 id="4-cross-attention-mechanism✨"><a href="#4-cross-attention-mechanism✨" class="headerlink" title="4. cross-attention mechanism✨:"></a>4. cross-attention mechanism✨:</h2><p>概括：在上文中提到的注意力机制中，每个注意力层都只包括了1个self-attention、1个cross-attention，并在这1个cross-attention中注入”由文本提升和图像提示融合得到的条件特征”【融合条件特征作为cross-attention的 Key&#x2F;Value】。由此出发的改进策略：将<strong>注意力解耦</strong>，即把“文本条件特征”与“图像条件特征”分开，分别注入到2个不同的cross-attention中去，再进行相加。</p><p>优点：图像提示拥有了与文本提示“同等地位”的控制权，能够更好的听图像提示的话！</p><p>论文举例：</p><ul><li><p><a href="http://arxiv.org/abs/2308.06721">IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models</a>-2023.8 腾讯✨</p><ul><li><p>策略：利用<strong>CLIP-image-encoder</strong>提取具有图像的image-feature，经过<strong>Linear+LayerNorm</strong>，将<strong>注意力解耦</strong>，即把“文本条件特征”与“图像条件特征”分开，分别注入到2个不同的cross-attention中去[ <em>text-cross-attention与image-cross-attention</em> ]，再将2个cross-attention结果进行相加。</p><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109143750831.png" alt="image-20250109143750831"></p></li></ul></li><li><p><a href="http://arxiv.org/abs/2403.11781">Infinite-ID: Identity-preserved Personalization via ID-semantics Decoupling Paradigm</a>-2024.3 中科大 没开源</p><ul><li>策略：与IP-A类似，只不过在imgae-feature提取这有所增添：除了来自CLIP-image-encoder提取的人像信息【后续称为clip-image-embedding】，还使用了来自<strong>人脸识别器</strong>提取的face-embedding，并将两者<strong>拼接concat</strong>，拼接后一齐作为图像条件特征（<strong>IP-A</strong>）。</li><li>训练策略：训练时，只使用图像输入，不使用caption。据说能够增强对图像的学习。</li><li>除此之外，风格控制方面还使用了AdaIN-m机制，主要是在self-attention上做了改动。</li><li><img src="/../imgs/personalization-and-feature-mechanism/image-20250109152153105.png" alt="image-20250109152153105"></li></ul></li><li><p><a href="http://arxiv.org/abs/2401.07519">InstantID: Zero-shot Identity-Preserving Generation in Seconds</a>-2024.2 InstantX、小红书</p><ul><li><p>策略：与Infinite-ID类似，也是在图像特征提取上做了改动：直接放弃CLIP-image-encoder，只使用人脸模型提取的face-embedding作为图像条件特征（<strong>IP-A</strong>）。除此之外，还使用了人脸关键点图结合<strong>ControlNet</strong>进行人脸五官位置的结构控制。</p></li><li><blockquote><p>注意：ControlNet不再使用text-embedding，只使用face-embedding。</p></blockquote></li></ul></li></ul><h2 id="5-double-UNet-mechanism✨"><a href="#5-double-UNet-mechanism✨" class="headerlink" title="5. double UNet mechanism✨:"></a>5. double UNet mechanism✨:</h2><p>概括：经过大量数据预训练的diffusion model本身已经具有了很强大的对图像提取特征的能力，那可以直接拿来替换&#x2F;作为上文的各种image-encoder啊！具体从哪层”拿“还挺值得研究，下面的两篇都是拿的ref_unet中的self-attention输出的feature，<strong>？？？？为什么呢</strong>。</p><p>论文举例：</p><ul><li><p><a href="http://arxiv.org/abs/2306.00973">Intelligent Grimm – Open-ended Visual Storytelling via Latent Diffusion Models</a>-2024.3 已开源✨</p><ul><li>策略：可以理解为IP-A的变种：依然是解耦的cross-attention，不过新增的image-cross-attention的keys&#x2F;values不再是直接用image-encoder提取的image-feature，用的是参考图像的”ref_unet”流程中<strong>ref-self-attention后得到的ref-unet-feature</strong>。</li></ul><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109164719609.png" alt="image-20250109164719609"></p></li><li><p>[Improving Diffusion Models for Authentic Virtual Try-on in the Wild]([<a href="https://arxiv.org/abs/2403.05139">2403.05139] Improving Diffusion Models for Authentic Virtual Try-on in the Wild</a>)-2024.3 KAIST 已开源✨</p><ul><li>策略：本文拿的也是”ref_unet”流程中<strong>ref-self-attention后得到的ref-unet-feature</strong>，与Intelligent Grimm不同的是：本文不再将其作为cross-attention的keys&#x2F;values，而是与hidden-states拼接作为新的Query作用到self-attention。</li><li>疑问：关于high-level、low-level如何理解？</li></ul></li></ul><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109173953044.png" alt="image-20250109173953044" title="IDM–VTON结构"></p><h2 id="6-novel-loss"><a href="#6-novel-loss" class="headerlink" title="6. novel loss"></a>6. novel loss</h2><p>在diffusion中常见的loss是：由unet预测到的噪声与真实噪声之间的MSE均方差loss，被称作vanilla-loss或naive-loss：</p><p><img src="/../imgs/personalization-and-feature-mechanism/image-20250109160403306.png" alt="image-20250109160403306"></p><p>论文举例：</p><ul><li><a href="http://arxiv.org/abs/2404.16022">PuLID: Pure and Lightning ID Customization via Contrastive Alignment</a>-2024.4 字节<ul><li>策略：利用加速模型（如Lightning T2I），在训练过程中增加对比loss，不对原模型能力做出破坏。<strong>IP-A</strong>+ <strong>Lightning T2I</strong>+使用额外的loss设计，包括在unet内部的aligh_loss和unet外部的id_loss；</li><li>优点：一个路径仅受提示的条件，而另一个路径使用ID和提示作为条件。通过在语义上对齐这两条路径上的UNET特征（即，Qt与Qtid），模型将学习如何在不影响原始模型行为的情况下嵌入ID。</li><li>缺点：增加耗时。？</li></ul></li></ul><p>​<img src="/../imgs/personalization-and-feature-mechanism/image-20250109161049551.png" alt="image-20250109161049551"></p><p>​<img src="/../imgs/personalization-and-feature-mechanism/image-20250109161355622.png" alt="image-20250109161355622"></p><p>待看：</p><p><a href="http://arxiv.org/abs/2406.16537">Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization</a>-2024.6</p>]]></content>
    
    
    <categories>
      
      <category>技术路线总结</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diffusion;</tag>
      
      <tag>control;</tag>
      
      <tag>text-to-img;</tag>
      
      <tag>img-to-img;</tag>
      
      <tag>大模型；</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>paper reading: Nested Attention: Semantic-aware Attention Values for Concept Personalization-2025</title>
    <link href="/paper-reading/paper-reading/"/>
    <url>/paper-reading/paper-reading/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://snap-research.github.io/NestedAttention/">文章链接</a></p></blockquote><p>关键概括：injects a rich and expressive image representation into the model’s existing cross-attention layers. &#x3D;&#x3D;&gt;  <strong>single textual-token</strong>、<strong>cross-attention: Nested Attention</strong>、 <strong>smaller semantic visual elements</strong>、 <strong>多个定制化概念</strong>、<strong>可以非人 数据集低需求</strong>  </p><p>personalization技术发展路线：text-embedding&#x2F;fine-tuning based——&gt;cross-image attention based——&gt;<em><strong>encoder-based（本文）</strong></em>✨</p><span id="more"></span><h2 id="1-如何理解per-query-attention-values"><a href="#1-如何理解per-query-attention-values" class="headerlink" title="1. 如何理解per-query attention values?"></a>1. 如何理解per-query attention values?</h2><h3 id="回顾cross-attention"><a href="#回顾cross-attention" class="headerlink" title="回顾cross-attention"></a>回顾cross-attention</h3><p>Query: hidden_states(来自unet中间层)</p><p>Key &amp; Value: text_embedding(来自text-encoder)</p><p>Q 与 K 的点积意义：表示当前空间位置下的 Q_ij 与 K 的语义相似性，即权重，用来后续与 V 加权。由此，在给定文本（K &#x2F; V ）下，Q的能够决定图像内容的“空间位置”，也就是控制了图像的“外观”！这是文章着重研究 Query 的原因。</p><p><img src="/../imgs/paper-reading/image-20250108160404745.png" alt="cross-attention" title="cross-attention"></p><h3 id="per-query-attention-Values"><a href="#per-query-attention-Values" class="headerlink" title="per-query attention Values"></a>per-query attention Values</h3><p>原文提取：per-query attention Values &#x3D; localized values that depend on the queries&#x3D;per-region values&#x3D;query-dependent values</p><p>Value: text_embedding(来自text-encoder)，由于 Value由不同的token对应的embedding组成，而一个token却要指示着图片<em>整个区域</em>的全部相关实例和相关内容，这很“粗粒度”，无法达到任务期待的“细粒度”个性化生成【value中的每一个embedding要负责整个query，任务重，容易完成的不好】。因此把任务细分：划分query，每个子query由专门的新value负责，减轻了value的任务量。即：提出了更局部的“localized Values”：能更好的关注到局部区域、细粒度的语义信息。</p><p>所谓的“per-query attention Values”具体是怎样实现的就是下面的内容了。</p><blockquote><p>注意：per-query attention Values ≠ attention map的值，Values指的是Q K V中的V。</p></blockquote><h2 id="2-如何理解nested-attention-mechanism？"><a href="#2-如何理解nested-attention-mechanism？" class="headerlink" title="2. 如何理解nested attention mechanism？"></a>2. 如何理解nested attention mechanism？</h2><p>其中公式1就是上文的“per-query attention Values”的实现方式了。简单来说，就是对special token（s*）在不同的空间位置（i,j）下的q_ij，单独预测value_ij，这样得到的value_ij便具有了更局部的、细粒度的语义信息。但不是所有的text token都是用这个机制，只有要被个性化的special token会用到，这种注意力机制就是nested attention mechanism。</p><p><img src="/../imgs/paper-reading/image-20250108165121686.png" alt="公式1&#x2F;2&#x2F;3" title="公式1&#x2F;2&#x2F;3"></p><blockquote><p>注意，Key 在公式1和3中的区别！(从左到右分别：公式1&#x2F;2&#x2F;3)<br>文中还提到了对“per-query attention Values”的正则化实验技巧，不具体介绍。</p></blockquote><h2 id="3-q-ij、nested-keys、nested-values从哪来？——可训练模块"><a href="#3-q-ij、nested-keys、nested-values从哪来？——可训练模块" class="headerlink" title="3. q_ij、nested keys、nested values从哪来？——可训练模块"></a>3. q_ij、nested keys、nested values从哪来？——可训练模块</h2><p>Q-Former得到：”Q-Former learned queries“，即q_ij；</p><p>nested attention layers[ linear layers ]得到：nested keys、nested values；</p><p>上述两个模块组成了文章的可训练部分，得到的q_ij、nested keys、nested values三者构成公式1的输入。</p><blockquote><p>注意：per-query attention Values ≠ nested values, 二者关系：nested values 和 nested keys 经过公式1 得到per-query attention Values。</p><p>clip image features &#x3D; CLIP ‘s last layer before pooling</p></blockquote><p><img src="/../imgs/paper-reading/image-20250108172150828.png" alt="论文架构" title="论文架构"></p><h2 id="4-对“Q-Former-learned-queries”的验证："><a href="#4-对“Q-Former-learned-queries”的验证：" class="headerlink" title="4. 对“Q-Former learned queries”的验证："></a>4. 对“Q-Former learned queries”的验证：</h2><p>从生成过程中的Query中取3个不同空间位置的q_ij，与nested keys进行点积运算得到attention map’，可以观察到总能有1-2个nested token与q_ij最相关；进一步将q_ij、nested keys、nested values按照公式1进行运算，得到Q-Former learned queries，与输入脸部图像的clip image features 进行点积运算得到attention map, 能直观的观察到Q-Former learned queries的作用，即生成的细粒度特征在输入图中的来源相关性。</p><p><img src="/../imgs/paper-reading/image-20250108174006292.png" alt="可视化验证" title="可视化验证"></p>]]></content>
    
    
    <categories>
      
      <category>paper_reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>attention</tag>
      
      <tag>diffusion</tag>
      
      <tag>text-to-img</tag>
      
      <tag>personalization</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>影视剧、书籍、音乐和生活方式推荐</title>
    <link href="/live/my_attitude/"/>
    <url>/live/my_attitude/</url>
    
    <content type="html"><![CDATA[<p>影视剧、书籍、音乐和生活方式推荐</p><p>下面会介绍我推荐的、我最近在看的影视剧、书籍、音乐和生活方式，说实话我认为这种“生活态度”的安利是极具私人性的，毕竟，它们组成了我个人。不过我不介意，因为我更看重它们对我来说的其他意义：记忆和成长。因此我会持续更新的~ </p><p>不论是想要了解我还是想要接受我的安利，都请继续关注吧！ </p><h2 id="影视"><a href="#影视" class="headerlink" title="影视"></a>影视</h2><h3 id="电影"><a href="#电影" class="headerlink" title="电影"></a>电影</h3><ul><li><a href="https://movie.douban.com/subject/36445098/">还有明天</a> 2023<br>观影过程中以为和国内<a href="https://movie.douban.com/subject/36587974/">出走的决心-2024</a>剧情类似，结果！我还是太狭隘了！！强烈推荐</li><li><a href="https://movie.douban.com/subject/26656728/">老娘与海 <strong>又名：泳者之心</strong></a> 2024</li><li><a href="https://movie.douban.com/subject/25821498/">妇女参政论者</a> 2015</li></ul><h3 id="连续剧"><a href="#连续剧" class="headerlink" title="连续剧"></a>连续剧</h3><ul><li><a href="https://movie.douban.com/subject/1474087/">无耻之徒</a> 2004-2020 <strong>忽略frank的不负责任真的是最爱frank！</strong></li><li><a href="https://book.douban.com/subject/27204805/">我的天才女友(意大利)</a> 2018-2024<br>关键词：书籍《那不勒斯四部曲》改编：我的天才女友、新名字的故事、离开的，留下的、失踪的孩子<br>很细腻的女性作家书写的两名女性的友谊：复杂、既有爱又有恨和期待；很喜欢两个女生以各自的速度成长。</li><li><a href="https://movie.douban.com/subject/26838164/">伦敦生活</a> 2016-2019</li><li><a href="https://movie.douban.com/subject/36085524/">影后(台湾)</a> 2024 <strong>太爱杨谨华！</strong></li><li><a href="">人生复本</a>:看过<a href="">瑞克和莫蒂</a>的应该不会被这个电影惊艳到，’薛定谔的猫’系列科幻片 2025.2</li></ul><h3 id="动漫"><a href="#动漫" class="headerlink" title="动漫"></a>动漫</h3><ul><li>刺客伍六七：超级轻松搞笑！！！</li></ul><h2 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h2><ul><li><a href="https://book.douban.com/subject/25836270/">厌女：日本的女性厌恶——上野千鹤子</a> 2015<br>关键词：男性同性社会性欲望homosocial、厌女misogyny、同性恋憎恶homophobia、厌女症：男性对女性的蔑视和女性的自我厌恶<br>理论性还是比<a href="https://book.douban.com/subject/35523099/?icn=index-latestbook-subject">从零开始的女性主义</a>要高得多，而且翻译感好重，什么时候国内女性主义作家能把<a href="https://book.douban.com/subject/6722209/">男人之间</a>用国内的历史和语言文化，在近代的情况下进行更新的分析呢？希望！</li><li><a href="https://book.douban.com/subject/35966120/?icn=index-topchart-subject">始于极限——上野千鹤子</a> 2022 <strong>正在阅读</strong></li><li><a href="https://book.douban.com/subject/35143790/">蛤蟆先生去看心理医生——罗伯特·戴博德</a> 2020 <strong>第二次阅读</strong></li><li><a href="">双重赔偿</a> 2个小时就能看完的精彩小说！2025.2</li></ul><h2 id="音乐"><a href="#音乐" class="headerlink" title="音乐"></a>音乐</h2><ul><li>歌手：</li><li>别野加奈：很适合专注时的背景音会，让人平静下来</li></ul><h2 id="生活方式"><a href="#生活方式" class="headerlink" title="生活方式"></a>生活方式</h2><h3 id="播客："><a href="#播客：" class="headerlink" title="播客："></a>播客：</h3><ul><li>文化有限：每期对应一本<strong>书</strong></li><li>凹凸电波：搞笑的一群朋友们闲谈，听起来轻松</li><li>燕外之意：针对某一主题对网友的经历汇总</li><li>思文败类：轻松+小思考</li><li>随机波动：感性、深邃的女性在谈论中思考</li><li>岩中花述：鲁豫的对谈，最近都是”she”她主题的女性嘉宾</li></ul><h3 id="运动："><a href="#运动：" class="headerlink" title="运动："></a>运动：</h3><ul><li>健身：争取引体向上</li><li>攀岩：新时代不分性别的”裹小脚”</li><li>网球：希望对球的控制更稳定一些</li><li>游泳：谁能想到每周都在坚持游泳！</li></ul><p><img src="/../imgs/roy.jpg" alt="王源图片" title="roy"></p><blockquote><p>github: <a href="https://pljj315.github.io/">pljj315</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>live</category>
      
    </categories>
    
    
    <tags>
      
      <tag>安利</tag>
      
      <tag>影视剧</tag>
      
      <tag>书籍</tag>
      
      <tag>音乐</tag>
      
      <tag>生活方式</tag>
      
      <tag>recommends</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
